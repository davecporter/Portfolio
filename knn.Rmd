## K NEAREST NEIGHBOURS 

To better understand how the k nearest neighbours algorthimn works, I've built it from scratch and checked the results of my function to that of class::knn. 

My function is set up to work with two predictors, `p1` and `p2`, each having two classes, `A` and `B`, randomly generated from normal distributions.

```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(class)
```

Set input parameters. Group A mean of -0.5 and group B mean of 0.5 works well to separate the groups enough .
```{r}
# seed for random data generation
global_seed <- 21789 # runif(1)*1e6)
# number of training observations
n_train <- 100
# number of test observations
n_test <- 10
# group A normal distribution mean and standard deviation
gpA_mu_sd <- c(-0.5, 1)
# groupd B normal distribution mean and standard deviation
gpB_mu_sd <- c(0.5, 1)
```

Create training data frame. Note there is no need to scale variables as data are generated using `rnorm()`.
```{r}
set.seed(global_seed)
gpA = data.frame(gp = "A", 
                 p1 = rnorm(n_train, mean=gpA_mu_sd[1], sd=gpA_mu_sd[2]), 
                 p2 = rnorm(n_train, mean=gpA_mu_sd[1], sd=gpA_mu_sd[2]), 
                 stringsAsFactors = FALSE)
gpB = data.frame(gp = "B", 
                 p1 = rnorm(n_train, mean=gpB_mu_sd[1], sd=gpB_mu_sd[2]), 
                 p2 = rnorm(n_train, mean=gpB_mu_sd[1], sd=gpB_mu_sd[2]), 
                 stringsAsFactors = FALSE)
train = bind_rows(gpA, gpB)
# ggplot(train, aes(p1, p2, col=gp)) + geom_point()
```

Create test data frame.
```{r}
set.seed(global_seed + 1) # +1 enables generation of different test data to train
test_Xp <- data.frame(p1 = rnorm(n_test, mean=-0.5), p2 = rnorm(n_test, mean=-0.5), stringsAsFactors = FALSE)
groups <- data.frame(gp = paste("y_hat", seq(1, n_test), sep = ""), stringsAsFactors = FALSE)
test <- cbind(test_Xp, groups)
```

knn algorithm, outputs vector of predictions and plot of train/test data. Hollow circles are training data, solid cirlces are test predictions.
```{r}
knn_func <- function(train, test, k, seed=round(runif(1)*1e6)){
  # calculate euclidean distances
  distances <- dist(rbind(test, train)) %>% as.matrix()
  colnames(distances) <- rownames(distances) <- c(test[["gp"]], train[["gp"]])
  n_test <- nrow(test)
  
  # selects nearest k neighbours
  knn_predict <- function(){
    set.seed(seed) # used to randomly select ties
    distances[,1:n_test] %>% as.data.frame() %>% mutate(gp = rownames(.)) %>% 
      gather("y_hat", "dist", contains("y_hat")) %>% 
      filter(!str_detect(gp, "y_hat")) %>% 
      group_by(y_hat) %>% 
      top_n(-k) %>% 
      # randomly choose between ties
      count(gp) %>% 
      mutate(n = n + runif(1)) %>% 
      filter(n == max(n)) %>% 
      mutate(n = round(n))
  }
  
  # run `knn_predict()` and put predictions in same order as `test` input
  knn_pred <- knn_predict() %>% select(-n) %>% 
    mutate(pred_no = str_replace_all(y_hat, "y_hat", "") %>% as.numeric()) %>% arrange(pred_no)
  
  plotr <- left_join(knn_pred, test %>% rename(y_hat = gp))
  plot <- ggplot() + geom_point(data = train, aes(p1, p2, col=gp), shape=1) +
    geom_point(data = plotr, aes(p1, p2, col=gp), size=2)
  
  list(knn_pred %>% pull(gp), plot)
}
```

```{r}
knn_func_results <- knn_func(train, test, k=5)
knn_func_results
```

Compare results of `knn_func()` to `knn()`
```{r}
set.seed(global_seed)
train_X <- train %>% select(p1, p2)
train_y <- train %>% pull(gp)

knn_results <- knn(train_X, test[,-3], train_y, 5)

data.frame(knn_func_results[[1]], knn_results) %>% mutate(same_result = .[,1] == .[,2])
```

Future considerations:
- identify train and test sets in plot legend